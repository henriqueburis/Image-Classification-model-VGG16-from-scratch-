{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henriqueburis/Image_Classification_model_VGG16_from_scratch/blob/main/Classification_vgg16from_scrapt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3bdyu0huye_"
      },
      "source": [
        "Deep learning CNN-VGG16 from scrapt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yf2CjFYXCnTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5de38b0-3993-4a6f-c43a-b5fb2028b6e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQsWsPBnKcB-"
      },
      "outputs": [],
      "source": [
        "#!rm -rf /content/UCMerced_LandUse_pixforce_threeClasse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSoK-KtSGOkq"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/UCMerced_LandUse_pixforce_threeClasse.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLqpAQtLPLM-"
      },
      "outputs": [],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pIt-ztWU1GMN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tensorboardX import SummaryWriter\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5zeAHd-1_DT",
        "outputId": "ba2f604e-355f-4d8b-fb92-bcfdadb92a0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Parametre data\n"
          ]
        }
      ],
      "source": [
        "print(\"==> Parametre data\")\n",
        "img_size = 227\n",
        "batch_size = 32\n",
        "batch_size_inferencia = 1\n",
        "n_classe = 0\n",
        "epoch = 200\n",
        "\n",
        "path_train = \"/content/UCMerced_LandUse_pixforce_threeClasse/train\"\n",
        "path_test = \"/content/UCMerced_LandUse_pixforce_threeClasse/Images\"\n",
        "save_dir = \"/content/drive/MyDrive/results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjrk6-ti1S37",
        "outputId": "c03aefb1-2da5-442f-ef4c-5810eff21de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n"
          ]
        }
      ],
      "source": [
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((img_size,img_size)),\n",
        "    #transforms.RandomCrop(32, padding=4), # testar sem o randomcrop.\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((img_size,img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "\n",
        "trainset = datasets.ImageFolder(os.path.abspath(path_train), transform=transform_train)\n",
        "\n",
        "train, valid = torch.utils.data.random_split(trainset,[243,27]) #10%test\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(valid,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False, num_workers=0)\n",
        "\n",
        "testset = datasets.ImageFolder(os.path.abspath(path_test), transform=transform_test)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size_inferencia,\n",
        "                                         shuffle=False, num_workers=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "LNpv7Oc2mU1C",
        "outputId": "e571c3d8-d6aa-4e57-dea6-6a8ed53d9040"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classe do treinamento==)> ['agricultural', 'buildings', 'forest']\n",
            "Num_ Classe==)> 3\n",
            "Dataset Train 243\n",
            "Dataset Val 27\n",
            "------------------------------------------------\n",
            "==> Preparing data Done..\n"
          ]
        }
      ],
      "source": [
        "classes =  train_loader.dataset.dataset.classes\n",
        "num_label = train_loader.dataset.dataset.targets\n",
        "n_classe = len(classes)\n",
        "a = num_label.count(0)\n",
        "b = num_label.count(1)\n",
        "c = num_label.count(2)\n",
        "y_pos = np.arange(len(classes))\n",
        "performance = [a,b,c]\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, classes)\n",
        "plt.ylabel('samples')\n",
        "plt.title('Train')\n",
        "plt.savefig('balanced.png')\n",
        "plt.show()\n",
        "print(\"Classe do treinamento==)>\",classes)\n",
        "print(\"Num_ Classe==)>\",n_classe)\n",
        "print(\"Dataset Train\",len(train_loader.dataset.indices))\n",
        "print(\"Dataset Val\",len(val_loader.dataset.indices))\n",
        "print(\"------------------------------------------------\")\n",
        "print('==> Preparing data Done..')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class vgg16scratch(nn.Module):\n",
        "    def __init__(self, num_classes=0):\n",
        "        super(vgg16scratch, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),nn.ReLU(),\n",
        "            nn.BatchNorm2d(64), \n",
        "            nn.MaxPool2d((2,2), stride=(2,2)), # pool de janela quadrada de tamanho = 2, passo = 2\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d((2,2), stride=(2,2)), # pool de janela quadrada de tamanho = 2, passo = 2\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.MaxPool2d((2,2), stride=(2,2)), # pool de janela quadrada de tamanho = 2, passo = 2\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),nn.ReLU(),\n",
        "            nn.MaxPool2d((2,2), stride=(2,2)), # pool de janela quadrada de tamanho = 2, passo = 2\n",
        "        )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),nn.ReLU(),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),nn.ReLU(),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),nn.ReLU(),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.MaxPool2d((2,2), stride=(2,2)), # pool de janela quadrada de tamanho = 2, passo = 2\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(7*7*512, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        #print(out.shape)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "dnEOSfWmG0rr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtXeLjbB1401",
        "outputId": "e7c928f7-3e27-43e9-daee-6f089e0a89fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Building model..\n",
            "vgg16scratch(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU()\n",
            "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer5): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU()\n",
            "    (8): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=0, bias=True)\n",
            "  )\n",
            ")\n",
            "-------------------\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print('==> Building model..')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "net = vgg16scratch(n_classe).to(device)\n",
        "\n",
        "print(net)\n",
        "\n",
        "net = net.to(device)\n",
        "\n",
        "print(\"-------------------\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uFmpWbQ3ObW"
      },
      "source": [
        "https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vj60HsZJ2edP"
      },
      "outputs": [],
      "source": [
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "criterion_cnn = nn.CrossEntropyLoss()\n",
        "optimizer_cnn = optim.Adam(net.parameters(), lr=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UpKB4WlMGp_d"
      },
      "outputs": [],
      "source": [
        "def save_model(model):\n",
        "    torch.save(model.state_dict(), save_dir + \"/\"\"pixforce_model.pt\")\n",
        "\n",
        "def CreateDir(path):\n",
        "        try:\n",
        "                os.mkdir(path)\n",
        "        except OSError as error:\n",
        "                print(error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo1V9kavUqvp",
        "outputId": "ca864133-917a-4569-da6b-fa0dfd57a031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 17] File exists: '/content/drive/MyDrive/results'\n"
          ]
        }
      ],
      "source": [
        "CreateDir(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af46xa6iLRXR",
        "outputId": "7f960a2d-6df8-4aba-b145-96f4bb116da8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing tensorboard..\n"
          ]
        }
      ],
      "source": [
        "print('==> Preparing tensorboard..')\n",
        "writer = SummaryWriter(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tiTkVtQj219b"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer_cnn.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion_cnn(outputs, targets)# criterion\n",
        "        loss.backward()\n",
        "        optimizer_cnn.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        writer.add_scalar('Training/ACC_',100.*correct/total, (epoch*len(train_loader.dataset)/batch_size)+batch_idx)\n",
        "        writer.add_scalar('Training/loss_',train_loss/(batch_idx+1),(epoch*len(train_loader.dataset)/batch_size)+batch_idx)\n",
        "    print('\\n %d',correct/total*100)\n",
        "    writer.add_scalar('Training/ACC',correct/total*100, epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "a4HK4ejWt6F7"
      },
      "outputs": [],
      "source": [
        "def val():\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100.*correct/total\n",
        "    print(\"ACC_test\",acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHJDBPdA3shs",
        "outputId": "a1cdc291-6a73-4d4d-e97d-2f6e1bc62816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([19, 25088])\n",
            "\n",
            " %d 99.58847736625515\n",
            "\n",
            "Epoch: 1\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([19, 25088])\n",
            "\n",
            " %d 99.58847736625515\n",
            "\n",
            "Epoch: 2\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([19, 25088])\n",
            "\n",
            " %d 99.58847736625515\n",
            "\n",
            "Epoch: 3\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([19, 25088])\n",
            "\n",
            " %d 100.0\n",
            "\n",
            "Epoch: 4\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([19, 25088])\n",
            "\n",
            " %d 99.58847736625515\n",
            "\n",
            "Epoch: 5\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([19, 25088])\n",
            "\n",
            " %d 100.0\n",
            "\n",
            "Epoch: 6\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([19, 25088])\n",
            "\n",
            " %d 100.0\n",
            "\n",
            "Epoch: 7\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([19, 25088])\n",
            "\n",
            " %d 100.0\n",
            "\n",
            "Epoch: 8\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([32, 25088])\n",
            "torch.Size([19, 25088])\n",
            "\n",
            " %d 100.0\n",
            "torch.Size([27, 25088])\n",
            "ACC_test 100.0\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(0, epoch):\n",
        "  train(epoch)\n",
        "\n",
        "#print(\"--------------\")\n",
        "val()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}